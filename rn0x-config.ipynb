{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: nvidia-smi: command not found\n",
      "2024-04-24 17:00:28.702656: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 17:00:28.756206: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 17:00:28.756744: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 17:00:29.497605: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/hls4ml/converters/__init__.py:16: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "from asyncio import DatagramProtocol\n",
    "import os\n",
    "import json\n",
    "if os.system('nvidia-smi') == 0:\n",
    "    import setGPU\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import argparse\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Activation, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import hls4ml\n",
    "from qkeras.utils import _add_supported_quantized_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERF_SAMPLE = False\n",
    "\n",
    "def print_dict(d, indent=0):\n",
    "    align = 20\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key), end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_dict(value, indent+1)\n",
    "        else:\n",
    "            print(':' + ' ' * (20 - len(key) - 2 * indent) + str(value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " q_conv2d_batchnorm (QConv2  (None, 8, 8, 32)          1025      \n",
      " DBatchnorm)                                                     \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " q_conv2d_batchnorm_1 (QCon  (None, 8, 8, 32)          9377      \n",
      " v2DBatchnorm)                                                   \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 8, 8, 32)          0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_conv2d_batchnorm_2 (QCon  (None, 8, 8, 32)          9377      \n",
      " v2DBatchnorm)                                                   \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 8, 8, 32)          0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40269 (157.31 KB)\n",
      "Trainable params: 40074 (156.54 KB)\n",
      "Non-trainable params: 195 (792.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 574 images belonging to 10 classes.\n",
      "Found 574 images belonging to 10 classes.\n",
      "(574, 1, 32, 32, 3)\n",
      "574\n",
      "(18,)\n",
      "18\n",
      "18/18 [==============================] - 7s 326ms/step\n",
      "(574, 10)\n",
      "(574, 10)\n",
      "Keras Accuracy:  0.050522648083623695\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: q_conv2d_batchnorm, layer type: QConv2DBatchnorm\n",
      "Layer name: q_activation, layer type: QActivation\n",
      "Layer name: q_conv2d_batchnorm_1, layer type: QConv2DBatchnorm\n",
      "Layer name: q_activation_1, layer type: QActivation\n",
      "Layer name: q_conv2d_batchnorm_2, layer type: QConv2DBatchnorm\n",
      "Layer name: q_activation_2, layer type: QActivation\n",
      "Layer name: q_dense, layer type: QDense\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         ap_fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "LayerName\n",
      "  input_1\n",
      "    Precision\n",
      "      result:        ap_fixed<16,6>\n",
      "  q_conv2d_batchnorm\n",
      "    Precision\n",
      "      weight:        ap_fixed<8,3>\n",
      "      bias:          ap_fixed<8,3>\n",
      "    ReuseFactor:     1\n",
      "  q_activation\n",
      "    Precision\n",
      "      result:        ap_ufixed<8,2>\n",
      "    ReuseFactor:     1\n",
      "  q_conv2d_batchnorm_1\n",
      "    Precision\n",
      "      weight:        ap_fixed<8,3>\n",
      "      bias:          ap_fixed<8,3>\n",
      "    ReuseFactor:     1\n",
      "  q_activation_1\n",
      "    Precision\n",
      "      result:        ap_ufixed<8,2>\n",
      "    ReuseFactor:     1\n",
      "  q_conv2d_batchnorm_2\n",
      "    Precision\n",
      "      weight:        ap_fixed<8,3>\n",
      "      bias:          ap_fixed<8,3>\n",
      "    ReuseFactor:     1\n",
      "  q_activation_2\n",
      "    Precision\n",
      "      result:        ap_ufixed<8,2>\n",
      "    ReuseFactor:     1\n",
      "  q_dense\n",
      "    Precision\n",
      "      weight:        ap_fixed<8,3>\n",
      "      bias:          ap_fixed<8,3>\n",
      "    ReuseFactor:     1\n",
      "-----------------------------------\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 32, 32, 3]], output shape: [None, 32, 32, 3]\n",
      "Layer name: q_conv2d_batchnorm, layer type: QConv2DBatchnorm, input shapes: [[None, 32, 32, 3]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_activation, layer type: Activation, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_conv2d_batchnorm_1, layer type: QConv2DBatchnorm, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_activation_1, layer type: Activation, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_conv2d_batchnorm_2, layer type: QConv2DBatchnorm, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_activation_2, layer type: Activation, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 8, 8, 32]], output shape: [None, 2048]\n",
      "Layer name: q_dense, layer type: QDense, input shapes: [[None, 2048]], output shape: [None, 10]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_conv2d_batchnorm\" (Conv2DBatchnorm)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_conv2d_batchnorm\". Using ReuseFactor=864 instead. Valid ReuseFactor(s): 3,9,27,54,108,216,432,864.\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_conv2d_batchnorm_1\" (Conv2DBatchnorm)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_conv2d_batchnorm_1\". Using ReuseFactor=9216 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216.\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_conv2d_batchnorm_2\" (Conv2DBatchnorm)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_conv2d_batchnorm_2\". Using ReuseFactor=9216 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216.\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_dense\" (Dense)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_dense\". Using ReuseFactor=20480 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256,512,1024,2048,4096,10240,20480.\n",
      "-----------------------------------\n",
      "OutputDir:           ../inference/hls/pynqz2_resnet_m_axi_8_serial_prj\n",
      "ProjectName:         myproject\n",
      "Backend:             VivadoAccelerator\n",
      "XilinxPart:          xcku115-flvb2104-2-i\n",
      "Board:               pynq-z2\n",
      "ClockPeriod:         10\n",
      "IOType:              io_stream\n",
      "HLSConfig\n",
      "  Model\n",
      "    Precision:       ap_fixed<8,6>\n",
      "    ReuseFactor:     16384\n",
      "    Strategy:        Resource\n",
      "    MergedRelu:      1\n",
      "  LayerName\n",
      "    input_1\n",
      "      Precision:     ap_ufixed<8,0>\n",
      "      Trace:         True\n",
      "      ReuseFactor:   16384\n",
      "    q_conv2d_batchnorm\n",
      "      Precision\n",
      "        weight:      ap_fixed<8,3>\n",
      "        bias:        ap_fixed<8,3>\n",
      "        result:      ap_fixed<9,6>\n",
      "        default:     ap_fixed<9,6>\n",
      "      ReuseFactor:   16384\n",
      "      Trace:         True\n",
      "      force_dsp:     0\n",
      "      accum_t:       ap_fixed<14,6>\n",
      "    q_activation\n",
      "      Precision\n",
      "        default:     ap_fixed<9,6>\n",
      "        result:      ap_fixed<8,3,AP_RND,AP_SAT>\n",
      "      ReuseFactor:   16384\n",
      "      Trace:         True\n",
      "    q_conv2d_batchnorm_1\n",
      "      Precision\n",
      "        weight:      ap_fixed<8,3>\n",
      "        bias:        ap_fixed<8,3>\n",
      "        result:      ap_fixed<9,6>\n",
      "        default:     ap_fixed<9,6>\n",
      "      ReuseFactor:   16384\n",
      "      Trace:         True\n",
      "      force_dsp:     0\n",
      "      accum_t:       ap_fixed<14,6>\n",
      "    q_activation_1\n",
      "      Precision\n",
      "        default:     ap_fixed<9,6>\n",
      "        result:      ap_fixed<8,3,AP_RND,AP_SAT>\n",
      "      ReuseFactor:   16384\n",
      "      Trace:         True\n",
      "    q_conv2d_batchnorm_2\n",
      "      Precision\n",
      "        weight:      ap_fixed<8,3>\n",
      "        bias:        ap_fixed<8,3>\n",
      "        result:      ap_fixed<9,6>\n",
      "        default:     ap_fixed<9,6>\n",
      "      ReuseFactor:   16384\n",
      "      Trace:         True\n",
      "      force_dsp:     0\n",
      "      accum_t:       ap_fixed<14,6>\n",
      "    q_activation_2\n",
      "      Precision\n",
      "        default:     ap_fixed<9,6>\n",
      "        result:      ap_fixed<8,3,AP_RND,AP_SAT>\n",
      "      ReuseFactor:   16384\n",
      "      Trace:         True\n",
      "    q_dense\n",
      "      Precision\n",
      "        weight:      ap_fixed<8,3>\n",
      "        bias:        ap_fixed<8,3>\n",
      "        result:      ap_fixed<8,6>\n",
      "        default:     ap_fixed<8,6>\n",
      "      ReuseFactor:   16384\n",
      "      Trace:         True\n",
      "      force_dsp:     0\n",
      "      accum_t:       ap_fixed<12,6>\n",
      "    q_conv2d_batchnorm_linear\n",
      "      Precision\n",
      "        result:      ap_fixed<9,6>\n",
      "        default:     ap_fixed<9,6>\n",
      "    q_conv2d_batchnorm_1_linear\n",
      "      Precision\n",
      "        result:      ap_fixed<8,6>\n",
      "        default:     ap_fixed<8,6>\n",
      "    q_conv2d_batchnorm_2_linear\n",
      "      Precision\n",
      "        result:      ap_fixed<9,6>\n",
      "        default:     ap_fixed<9,6>\n",
      "  SkipOptimizers:    ['reshape_stream']\n",
      "AcceleratorConfig\n",
      "  Interface:         m_axi\n",
      "  Driver:            python\n",
      "  Precision\n",
      "    Input:           float\n",
      "    Output:          float\n",
      "InputData:           resnet_v1_eembc_RN06_2024_fo/X_test.npy\n",
      "OutputPredictions:   resnet_v1_eembc_RN06_2024_fo/y_test.npy\n",
      "KerasModel:          <keras.src.engine.functional.Functional object at 0x7f59f0798430>\n",
      "ApplyPatches:        1\n",
      "-----------------------------------\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 32, 32, 3]], output shape: [None, 32, 32, 3]\n",
      "Layer name: q_conv2d_batchnorm, layer type: QConv2DBatchnorm, input shapes: [[None, 32, 32, 3]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_activation, layer type: Activation, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_conv2d_batchnorm_1, layer type: QConv2DBatchnorm, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_activation_1, layer type: Activation, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_conv2d_batchnorm_2, layer type: QConv2DBatchnorm, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: q_activation_2, layer type: Activation, input shapes: [[None, 8, 8, 32]], output shape: [None, 8, 8, 32]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 8, 8, 32]], output shape: [None, 2048]\n",
      "Layer name: q_dense, layer type: QDense, input shapes: [[None, 2048]], output shape: [None, 10]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_conv2d_batchnorm\" (Conv2DBatchnorm)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_conv2d_batchnorm\". Using ReuseFactor=864 instead. Valid ReuseFactor(s): 3,9,27,54,108,216,432,864.\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_conv2d_batchnorm_1\" (Conv2DBatchnorm)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_conv2d_batchnorm_1\". Using ReuseFactor=9216 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216.\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_conv2d_batchnorm_2\" (Conv2DBatchnorm)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_conv2d_batchnorm_2\". Using ReuseFactor=9216 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216.\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"q_dense\" (Dense)\n",
      "WARNING: Invalid ReuseFactor=16384 with \"Resource\" strategy in layer \"q_dense\". Using ReuseFactor=20480 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256,512,1024,2048,4096,10240,20480.\n",
      "Recompiling myproject with tracing\n",
      "WARNING: You set a XilinxPart that does not correspond to the Board you specified. The correct XilinxPart is now set.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "================================================\n",
      "baord pynq-z2\n",
      "tcl_script None\n",
      "================================================\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "No tcl script definition available for the desired interface in supported_board.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 236\u001b[0m\n\u001b[1;32m    230\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutputDir\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofiling_numerical.png\u001b[39m\u001b[38;5;124m'\u001b[39m), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m#plt.figure()\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m#cp = compare(keras_model=model, hls_model=hls_model, X=X_test, plot_type=\"dist_diff\")\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m#plt.savefig(os.path.join(cfg['OutputDir'], 'profiling_compare.png'), dpi=300)\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m y_hls, hls4ml_trace \u001b[38;5;241m=\u001b[39m \u001b[43mhls_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_hls.npy\u001b[39m\u001b[38;5;124m'\u001b[39m), y_hls)\n\u001b[1;32m    238\u001b[0m keras_trace \u001b[38;5;241m=\u001b[39m hls4ml\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mprofiling\u001b[38;5;241m.\u001b[39mget_ymodel_keras(model, X_test)\n",
      "File \u001b[0;32m/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/hls4ml/model/hls_model.py:652\u001b[0m, in \u001b[0;36mHLSModel.trace\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecompiling \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_project_name()))\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrace_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m top_function, ctype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_top_function(x)\n\u001b[1;32m    655\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_n_samples(x)\n",
      "File \u001b[0;32m/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/hls4ml/model/hls_model.py:538\u001b[0m, in \u001b[0;36mHLSModel.compile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     curr_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m    541\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_output_dir())\n",
      "File \u001b[0;32m/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/hls4ml/model/hls_model.py:535\u001b[0m, in \u001b[0;36mHLSModel.write\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(choice(hexdigits) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length))\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m make_stamp()\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_hls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/hls4ml/writer/vivado_accelerator_writer.py:489\u001b[0m, in \u001b[0;36mVivadoAcceleratorWriter.write_hls\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvivado_accelerator_config \u001b[38;5;241m=\u001b[39m VivadoAcceleratorConfig(model\u001b[38;5;241m.\u001b[39mconfig, model\u001b[38;5;241m.\u001b[39mget_input_variables(),\n\u001b[1;32m    487\u001b[0m                                                          model\u001b[38;5;241m.\u001b[39mget_output_variables())\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28msuper\u001b[39m(VivadoAcceleratorWriter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite_hls(model)\n\u001b[0;32m--> 489\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_board_script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_driver(model)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_wrapper_test(model)\n",
      "File \u001b[0;32m/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/hls4ml/writer/vivado_accelerator_writer.py:334\u001b[0m, in \u001b[0;36mVivadoAcceleratorWriter.write_board_script\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03mWrite the tcl scripts to create a Vivado IPI project for the VivadoAccelerator\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    333\u001b[0m filedir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\n\u001b[0;32m--> 334\u001b[0m copyfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(filedir, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvivado_accelerator_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tcl_file_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    335\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/design.tcl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_output_dir()))\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvivado_accelerator_config\u001b[38;5;241m.\u001b[39mget_interface() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxi_master\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvivado_accelerator_config\u001b[38;5;241m.\u001b[39mboard \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marty-a7-100t\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    337\u001b[0m     copytree(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(filedir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvivado_accelerator_config\u001b[38;5;241m.\u001b[39mget_vivado_ip_wrapper_path()),\n\u001b[1;32m    338\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_output_dir()),\n\u001b[1;32m    339\u001b[0m              dirs_exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data1/jcampos/.conda/envs/tiny-rn07-env/lib/python3.8/site-packages/hls4ml/templates/vivado_accelerator_config.py:156\u001b[0m, in \u001b[0;36mVivadoAcceleratorConfig.get_tcl_file_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtcl_script\u001b[39m\u001b[38;5;124m'\u001b[39m, tcl_script)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m================================================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo tcl script definition available for the desired interface in supported_board.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../templates/vivado_accelerator/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboard \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tcl_scripts/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m tcl_script\n",
      "\u001b[0;31mException\u001b[0m: No tcl script definition available for the desired interface in supported_board.json"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "with open(\"config/RN06-Poke10.yml\") as stream:\n",
    "    our_config = yaml.safe_load(stream)\n",
    "save_dir = our_config['save_dir']\n",
    "model_file_path = os.path.join(save_dir, 'model_best.h5')\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "\n",
    "model = load_model(model_file_path, custom_objects=co)\n",
    "if bool(our_config['convert']['RemoveSoftmax']):\n",
    "    input_layer = model.inputs\n",
    "    output_layer = None\n",
    "    for layer in model.layers:\n",
    "        if layer.name == 'softmax':\n",
    "            output_layer = layer.input\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.save(model_file_path.replace('.h5', '_nosoftmax.h5'))\n",
    "\n",
    "apply_patches = bool(our_config['convert']['ApplyPatches'])\n",
    "if apply_patches:\n",
    "    inputs = Input((32, 32, 3), name='input_3')\n",
    "    x = tf.keras.layers.experimental.preprocessing.Rescaling(1/256, name='rescaling_1')(inputs)\n",
    "    outputs = model(x)\n",
    "    model_rescale = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model,\n",
    "                            to_file=os.path.join(save_dir, \"model.png\"),\n",
    "                            show_shapes=True,\n",
    "                            show_dtype=False,\n",
    "                            show_layer_names=False,\n",
    "                            rankdir=\"TB\",\n",
    "                            expand_nested=False)\n",
    "\n",
    "# to check on full dataset\n",
    "# _, (X_test, y_test) = cifar10.load_data()\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,\n",
    "    rescale=1./255 # normalize values to between 0-1\n",
    "    # preprocessing_function=random_crop,\n",
    "    #brightness_range=(0.9, 1.2),\n",
    "    #contrast_range=(0.9, 1.2)\n",
    ")\n",
    "test_generator = datagen.flow_from_directory('./data/PokeCard_2024/',\n",
    "                    target_size=(32,32),\n",
    "                    batch_size=1,\n",
    "                    color_mode='rgb',\n",
    "                    class_mode='categorical',\n",
    "                    interpolation='bilinear',\n",
    "                    shuffle=False)\n",
    "predict_test_generator = datagen.flow_from_directory('./data/PokeCard_2024/',\n",
    "                    target_size=(32,32),\n",
    "                    batch_size=32,\n",
    "                    color_mode='rgb',\n",
    "                    class_mode='categorical',\n",
    "                    interpolation='bilinear',\n",
    "                    shuffle=False)\n",
    "\n",
    "data_list = []\n",
    "batch_index = 0\n",
    "while batch_index <= test_generator.batch_index:\n",
    "    x_batch, y_batch = test_generator.next()\n",
    "    data_list.append(x_batch)\n",
    "    batch_index = batch_index + 1\n",
    "\n",
    "predict_data_list = []\n",
    "batch_index = 0\n",
    "while batch_index <= predict_test_generator.batch_index:\n",
    "    x_batch, y_batch = predict_test_generator.next()\n",
    "    predict_data_list.append(x_batch)\n",
    "    batch_index = batch_index + 1\n",
    "\n",
    "# now, data_array is the numeric data of whole images\n",
    "X_test = np.asarray(data_list, dtype=object)\n",
    "print(X_test.shape)\n",
    "print(len(data_list))\n",
    "y_test = np.asarray(test_generator.classes)\n",
    "\n",
    "Xp_test = np.asarray(predict_data_list, dtype=object)\n",
    "print(Xp_test.shape)\n",
    "print(len(predict_data_list))\n",
    "yp_test = np.asarray(predict_test_generator.classes)\n",
    "# to check on partial dataset\n",
    "if PERF_SAMPLE:\n",
    "    script_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    _idxs = np.load(os.path.join(script_dir, 'perf_samples_idxs.npy'))\n",
    "    X_test = X_test[_idxs]\n",
    "    y_test = y_test[_idxs]\n",
    "# use first 10 samples for building with FIFO Opt\n",
    "if bool(our_config['convert']['Build']) and bool(our_config['convert']['FIFO_opt']):\n",
    "    X_test = X_test[:10]\n",
    "    y_test = y_test[:10]\n",
    "# or just first 2 samples for building without FIFO Opt\n",
    "elif bool(our_config['convert']['Build']):\n",
    "    X_test = X_test[:2]\n",
    "    y_test = y_test[:2]\n",
    "num_samples = X_test.shape[0]\n",
    "\n",
    "X_test = np.ascontiguousarray(X_test, dtype=np.float32)\n",
    "if not apply_patches:\n",
    "    X_test = X_test/256.\n",
    "num_classes = 10\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Xp_test = np.ascontiguousarray(Xp_test, dtype=np.float32)\n",
    "#if not apply_patches:\n",
    "#    Xp_test = Xp_test/255.\n",
    "num_classes = 10\n",
    "yp_test = tf.keras.utils.to_categorical(yp_test, num_classes)\n",
    "y_test = yp_test\n",
    "if apply_patches:\n",
    "    y_keras = model_rescale.predict(predict_test_generator)\n",
    "else:\n",
    "    y_keras = model.predict(predict_test_generator)\n",
    "\n",
    "print(y_keras.shape)\n",
    "print(yp_test.shape)\n",
    "print(\"Keras Accuracy:  {}\".format(accuracy_score(np.argmax(yp_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "\n",
    "np.save(os.path.join(save_dir, 'y_keras.npy'), y_keras)\n",
    "np.save(os.path.join(save_dir, 'y_test.npy'), y_test)\n",
    "np.save(os.path.join(save_dir, 'X_test.npy'), X_test)\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "config['Model']['ReuseFactor'] = our_config['convert']['ReuseFactor']\n",
    "config['Model']['Strategy'] = our_config['convert']['Strategy']\n",
    "config['Model']['Precision'] = our_config['convert']['Precision']\n",
    "\n",
    "if bool(our_config['convert']['FIFO_opt']):\n",
    "    config['Model']['FIFO_opt'] = 1\n",
    "if bool(our_config['convert']['EEMBC_power']):\n",
    "    config['Model']['EEMBC_power'] = 1\n",
    "\n",
    "config['SkipOptimizers'] = ['reshape_stream']\n",
    "\n",
    "if bool(our_config['convert']['MergedRelu']):\n",
    "    config['Model']['MergedRelu'] = 1\n",
    "else:\n",
    "    config['SkipOptimizers'].append('relu_merge')\n",
    "\n",
    "for name in config['LayerName'].keys():\n",
    "    config['LayerName'][name]['Trace'] = bool(our_config['convert']['Trace'])\n",
    "    config['LayerName'][name]['ReuseFactor'] = our_config['convert']['ReuseFactor']\n",
    "    config['LayerName'][name]['Precision'] = our_config['convert']['Precision']\n",
    "# custom configs\n",
    "for name in our_config['convert']['Override'].keys():\n",
    "    if name not in config['LayerName'].keys():\n",
    "        config['LayerName'][name] = {}\n",
    "    config['LayerName'][name].update(our_config['convert']['Override'][name])\n",
    "\n",
    "\n",
    "backend = our_config['convert']['Backend']\n",
    "clock_period = our_config['convert']['ClockPeriod']\n",
    "io_type = our_config['convert']['IOType']\n",
    "interface = our_config['convert']['Interface']\n",
    "if backend == 'VivadoAccelerator':\n",
    "    board = our_config['convert']['Board']\n",
    "    driver = our_config['convert']['Driver']\n",
    "    input_type=our_config['convert']['InputType']\n",
    "    output_type = our_config['convert']['OutputType']\n",
    "    cfg = hls4ml.converters.create_config(backend=backend, board=board, interface=interface, clock_period=clock_period,\n",
    "                                            io_type=io_type, driver=driver, input_type=input_type, output_type=output_type)\n",
    "else:\n",
    "    part = our_config['convert']['XilinxPart']\n",
    "    cfg = hls4ml.converters.create_config(backend=backend, part=part, clock_period=clock_period,\n",
    "                                            io_type=io_type)\n",
    "cfg['HLSConfig'] = config\n",
    "cfg['InputData'] = os.path.join(save_dir, 'X_test.npy')\n",
    "cfg['OutputPredictions'] = os.path.join(save_dir, 'y_test.npy')\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir'] = our_config['convert']['OutputDir']\n",
    "cfg['ApplyPatches'] = our_config['convert']['ApplyPatches']\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "\n",
    "if our_config['convert']['FIFO_opt_json'] != \"None\":\n",
    "    with open(our_config['convert']['FIFO_opt_json'], 'r') as f:\n",
    "        maxs = json.load(f)\n",
    "\n",
    "    new_config = cfg.copy()['HLSConfig']\n",
    "    for k, v in hls_model.output_vars.items():\n",
    "        filtered_max = [x['max'] for x in maxs if v.cppname in x['name']]\n",
    "        if len(filtered_max) == 0:\n",
    "            continue\n",
    "        if len(filtered_max) > 1:\n",
    "            print('WARNING! Check names of FIFOs')\n",
    "        if k not in new_config['LayerName']:\n",
    "            new_config['LayerName'][k] = {'StreamDepth': filtered_max[0] + 1}\n",
    "        else:\n",
    "            new_config['LayerName'][k]['StreamDepth'] = filtered_max[0] + 1\n",
    "    for x in maxs:\n",
    "        if 'in_local' in x['name']:\n",
    "            new_config['LayerName']['in_local'] = {'StreamDepth': x['max'] + 1}\n",
    "        elif 'out_local' in x['name']:\n",
    "            new_config['LayerName']['out_local'] = {'StreamDepth': x['max'] + 1}\n",
    "    cfg['HLSConfig'] = new_config\n",
    "    hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print_dict(cfg)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# profiling / testing\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "\n",
    "os.makedirs(cfg['OutputDir'], exist_ok=True)\n",
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=os.path.join(cfg['OutputDir'], 'model_hls4ml.png'))\n",
    "\n",
    "if bool(our_config['convert']['Trace']):\n",
    "    from hls4ml.model.profiling import compare, numerical\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    X_test = np.squeeze(X_test, axis=1)\n",
    "    plt.figure()\n",
    "    # wp, wph, ap, aph = numerical(model=model, hls_model=hls_model, X=X_test)\n",
    "    plt.savefig(os.path.join(cfg['OutputDir'], 'profiling_numerical.png'), dpi=300)\n",
    "\n",
    "    #plt.figure()\n",
    "    #cp = compare(keras_model=model, hls_model=hls_model, X=X_test, plot_type=\"dist_diff\")\n",
    "    #plt.savefig(os.path.join(cfg['OutputDir'], 'profiling_compare.png'), dpi=300)\n",
    "\n",
    "    y_hls, hls4ml_trace = hls_model.trace(X_test)\n",
    "    np.save(os.path.join(save_dir, 'y_hls.npy'), y_hls)\n",
    "    keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X_test)\n",
    "\n",
    "    for layer in hls4ml_trace.keys():\n",
    "        plt.figure()\n",
    "        klayer = layer\n",
    "        if '_alpha' in layer:\n",
    "            klayer = layer.replace('_alpha', '')\n",
    "        plt.scatter(hls4ml_trace[layer].flatten(), keras_trace[klayer].flatten(), s=0.2)\n",
    "        min_x = min(np.amin(hls4ml_trace[layer]), np.amin(keras_trace[klayer]))\n",
    "        max_x = max(np.amax(hls4ml_trace[layer]), np.amax(keras_trace[klayer]))\n",
    "        plt.plot([min_x, max_x], [min_x, max_x], c='gray')\n",
    "        plt.xlabel('hls4ml {}'.format(layer))\n",
    "        plt.ylabel('QKeras {}'.format(klayer))\n",
    "        plt.savefig(os.path.join(cfg['OutputDir'], 'profiling_{}.png'.format(layer)), dpi=300)\n",
    "else:\n",
    "    hls_model.compile()\n",
    "    y_hls = hls_model.predict(X_test)\n",
    "\n",
    "#print(\"Keras Accuracy:  {}\".format(accuracy_score(np.argmax(yp_test, axis=1), np.argmax(yp_keras, axis=1))))\n",
    "#print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(yp_test, axis=1), np.argmax(y_hls, axis=1))))\n",
    "\n",
    "# Bitfile time\n",
    "if bool(our_config['convert']['Build']):\n",
    "    if bool(our_config['convert']['FIFO_opt']):\n",
    "        from hls4ml.model.profiling import optimize_fifos_depth\n",
    "        hls_model = optimize_fifos_depth(hls_model)\n",
    "        our_config['convert']['OutputDir'] = our_config['convert']['OutputDir'] + \"_FIFO_OPT\"\n",
    "        hls4ml.report.read_vivado_report(our_config['convert']['OutputDir'])\n",
    "    else:\n",
    "        hls_model.build(reset=False, csim=True, cosim=False, validation=False, synth=True, vsynth=False, export=True)\n",
    "        hls4ml.report.read_vivado_report(our_config['convert']['OutputDir'])\n",
    "    if our_config['convert']['Backend'] == 'VivadoAccelerator':\n",
    "        if our_config['convert']['Driver'] == 'c':\n",
    "            hls4ml.writer.vivado_accelerator_writer.VivadoAcceleratorWriter.write_header_file(\n",
    "                hls_model,\n",
    "                X_test.reshape(num_samples, -1),\n",
    "                y_test,\n",
    "                y_keras,\n",
    "                y_hls,\n",
    "                num_samples,\n",
    "                os.path.join(our_config['convert']['OutputDir'], 'sdk/common/data.h'))\n",
    "            \n",
    "        hls4ml.templates.VivadoAcceleratorBackend.make_bitfile(hls_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pynq-z2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny-rn06-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
